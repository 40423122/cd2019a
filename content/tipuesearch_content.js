var tipuesearch = {"pages": [{'title': '各組期末報告說明', 'text': '各組員必須在 W17 上課之前完成期末報告簡報影片上傳與連結, 並放入本網站之"專案口頭簡報"頁面. \n 各組必須在 W17 上課之前完成分組期末報告 pdf 檔案, 上傳至各分組的倉儲中, 並將連結提供至本網站之"專案報告書"頁面. \n 期末報告期間每週對各成員之評分依據下列要項: \n \n 各組員在各分組網站中所呈現之任務執行內容, 並拍攝操作影音 mp4, 將影片標題署名"國立虎尾科技大學-機械設計工程系-協同產品設計實習 A - 學號及影片主題" 後上傳, 並將影片嵌入本網站各章節頁面中. \n 每組將提供組長本網站倉儲協同管理權, 專門處理各組員在各分支或 master 分支中的 pull requests, 各組員必須透過以 ag1, ag2 .... 命名之分支對本倉儲改版, 確定內容無誤後, 再設法由組長處理各 pull requests 之內容合併, Github Pages 將設為與 master 分支對應, 各組員之評分將依據各 pull requests 中所列出之學號與內容判定. \n 請各組員勿將影片檔、圖片檔案或各式檔案送至本倉儲, 影片檔案請上傳至 Youtube, 圖片檔案請送至各組倉儲網站, 各式檔案則請送至各組員 Google Drive 區, 並以嵌入 (iframe), 將影片放入本網站, 其餘圖片或檔案則透過 img 或 a 標註放入各相關頁面. \n \n 2a 分組倉儲 \n https://github.com/mdekmol/cd2019a-task1-2019cda_t1_g1 \xa0( 2ag1 ) https://github.com/mdekmol/cd2019a-task1-2019cda_t1_g2 \xa0( 2ag2 ) https://github.com/mdekmol/cd2019a-task1-2019cda_t1_g3_1 \xa0( 2ag3 ) https://github.com/mdekmol/cd2019a-task1-2019cda_t1_g4 \xa0( 2ag4 ) https://github.com/mdekmol/cd2019a-task1-2019cda_t1_g5 \xa0( 2ag5 ) https://github.com/mdekmol/cd2019a-task1-2019cda_t1_g6 \xa0( 2ag6 ) \n', 'tags': '', 'url': '各組期末報告說明.html'}, {'title': '執行規劃', 'text': '', 'tags': '', 'url': '執行規劃.html'}, {'title': '手足球系統模擬', 'text': '專案成果摘要 \n 專案執行動機 \n 相關文獻探討 \n 專案執行成員 \n 執行使用套件 \n 專案執行過程規劃 \n 專案執行內容 \n 專案結論 \n', 'tags': '', 'url': '手足球系統模擬.html'}, {'title': '設計與繪圖', 'text': '', 'tags': '', 'url': '設計與繪圖.html'}, {'title': '零組件尺寸分析', 'text': '手足球系統的零組件尺寸分析 (可行性分析) \n', 'tags': '', 'url': '零組件尺寸分析.html'}, {'title': '參數設計與繪圖', 'text': '手足球系統的零組件參數設計與繪圖 (零組件初步設計繪圖) \n Onshape 零組件連結 \n \n \n', 'tags': '', 'url': '參數設計與繪圖.html'}, {'title': '細部設計與 BOM', 'text': '手足球零件格式說明 \n 手足球零件格式說明 \n 零件 BOM \n 手足球零組件材料表 (含零組件下載連結) \n 零件尺寸圖 \n 零件尺寸圖 \n 零件部分組裝圖 \n 零件部分組裝圖 \n 3D 零組件爆炸圖 \n 3D 零組件爆炸圖 \n', 'tags': '', 'url': '細部設計與 BOM.html'}, {'title': 'V-rep 動態模擬', 'text': '\n', 'tags': '', 'url': 'V-rep 動態模擬.html'}, {'title': 'Ag3-送球機構設計與模擬', 'text': "每周進度 \n W11進度 \n 本周進行人員分配工作，由 張育偉、洪明棋、林聖翰等三人所負責，在初步的討論下已有了各自的課題，由明棋負責送球軌道和球門下集球通道的設計及繪製，聖翰負責將球翻轉送上球檯的翻轉平台，而育偉則是Onshape的組裝以及V-rep的模擬，暫定將於三周內完成並將由其他成員完成程式的部分。 \n W12進度 \n 本周的進度是把送球機構的雛型加強，明棋將球門的斜度與寬度還有出球口重新做調整，聖翰將翻轉平台配合軌道重新調整了尺寸以及修正槽內的平台角度，育偉配合兩道球門的出球口與兩個反轉平台進球口架設兩條軌道。 \n W13進度 \n 本周進行由三人所繪製之零組件以及足球桌的組裝，組立上可以發現各組件上存在著許多配合上的誤差，從這裡可以看出組員之間的溝通並沒有妥善的說明清楚，這亦是協同設計上不可忽視的一點，其中軌道的部分修改最為多次，主要是因為與其連接的零組件定位方面須考慮非常多。 \n 討論 \n w11討論 \n 首先的問題是如何將球送上場地，一開始是以場地上方、下方以及兩側的位子出發去找出那個位置所對應的其合適的方法，場地上方是一開始就不去考慮的，在上方的話軌道會影響遊玩者的視線，而顯得有些礙眼；場地側面則是把手將其裝設的空間給佔據，受空間受限而改用其他位置來考慮，因此重點部分決定由下方來著手，下方有的問題該屬如何將場地諞面填平，想的方法千奇百怪甚至有點天馬行空，最終定案為由場地下方送球，在中心處挖洞設置一個翻轉的撥球平台。 \n w12討論 \n 本周的問題'將所有設計出來的機構調整尺寸到最佳化，球門方面調整了斜面以及送球口的尺寸，以便後續球在模擬時不會卡住，軌道將雛型設計出來並搭配球門與撥球平台。為了方便製造，原本兩個球門進球後會從撥球平台不同側經由軌道送入裡面，經過討論我們最後重新設計讓球都經由同一側進入撥球平台的槽中。 \n \xa0 \n", 'tags': '', 'url': 'Ag3-送球機構設計與模擬.html'}, {'title': '系統功能展示', 'text': '手足球模擬系統功能展示 (模擬展示與說明影片) \n', 'tags': '', 'url': '系統功能展示.html'}, {'title': 'Ag3-足球台模擬進度', 'text': '0506模擬測試 \n 40623105 \n \n \n 40623109 \n \n 40623118 \n \n \n 0513 模擬測試 \n 40623105 \n \n 40623109 \n \n 40623118 \n \n 0520 模擬測試 \n 40623105 \n 尺寸限制 \n \n 40623109 \n \n 40623118 \n \n \n 0522 模擬測試 \n 40623118 \n \n 0523 模擬測試 \n \n 0525 模擬測試 \n 40623109 \n \n \n', 'tags': '', 'url': 'Ag3-足球台模擬進度.html'}, {'title': 'Ag3-第十二週-影像辨識尋找球和桿子位置', 'text': '利用影像辨識系統尋找紅方、藍方和綠球的位置。 \n \n 程式利用 https://github.com/nemilya/vrep-api-python-opencv 改編而成 \n vrep設定檔: https://github.com/mdekmol/cd2019a-task1-2019cda_t1_g3_1/blob/master/v-rep/40623128/TableFootBall/v-rep/tablefootball - 0507.ttt \n 程式檔: https://github.com/mdekmol/cd2019a-task1-2019cda_t1_g3_1/blob/master/v-rep/40623128/TableFootBall/v-rep/Image_Detection_RGB.py \n 程式碼: \n import vrep\nimport time\n\nfrom PIL import Image as I\nimport array\n\nimport cv2, numpy\n\n# function based on: \n#   https://github.com/simondlevy/OpenCV-Python-Hacks/blob/master/greenball_tracker.py\ndef track_green_object(image):\n    # Blur the image to reduce noise100\n    blur = cv2.GaussianBlur(image, (5,5),0)\n    # Convert BGR to HSV\n    hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n    # Threshold the HSV image for only green colors\n    range = 15\n    lower_green = numpy.array([60-range,100,100])\n    upper_green = numpy.array([60+range,255,255])\n    # Threshold the HSV image to get only green colors\n    mask = cv2.inRange(hsv, lower_green, upper_green)\n    # Blur the mask\n    bmask = cv2.GaussianBlur(mask, (5,5),0)\n    # Take the moments to get the centroid\n    moments = cv2.moments(bmask)\n    m00 = moments[\'m00\']\n    centroid_x, centroid_y = None, None\n    if m00 != 0:\n        centroid_x = int(moments[\'m10\']/m00)\n        centroid_y = int(moments[\'m01\']/m00)\n    # Assume no centroid\n    ctr = None\n    # Use centroid if it exists\n    if centroid_x != None and centroid_y != None:\n        ctr = (centroid_x, centroid_y)\n    return ctr\n\ndef track_blue_object(image):\n    # Blur the image to reduce noise100\n    blur = cv2.GaussianBlur(image, (5,5),0)\n    # Convert BGR to HSV\n    hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n    # Threshold the HSV image for only green colors\n    range = 15\n    lower_red = numpy.array([0-range,100,100])\n    upper_red = numpy.array([0+range,255,255])\n    # Threshold the HSV image to get only green colors\n    mask = cv2.inRange(hsv, lower_red, upper_red)\n    # Blur the mask\n    bmask = cv2.GaussianBlur(mask, (5,5),0)\n    # Take the moments to get the centroid\n    moments = cv2.moments(bmask)\n    m00 = moments[\'m00\']\n    centroid_x, centroid_y = None, None\n    if m00 != 0:\n        centroid_x = int(moments[\'m10\']/m00)\n        centroid_y = int(moments[\'m01\']/m00)\n    # Assume no centroid\n    ctr = None\n    # Use centroid if it exists\n    if centroid_x != None and centroid_y != None:\n        ctr = (centroid_x, centroid_y)\n    return ctr\n    \ndef track_red_object(image):\n    # Blur the image to reduce noise100\n    blur = cv2.GaussianBlur(image, (5,5),0)\n    # Convert BGR to HSV\n    hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n    # Threshold the HSV image for only green colors\n    range = 15\n    lower_blue = numpy.array([120-range,100,100])\n    upper_blue = numpy.array([120+range,255,255])\n    # Threshold the HSV image to get only green colors\n    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n    # Blur the mask\n    bmask = cv2.GaussianBlur(mask, (5,5),0)\n    # Take the moments to get the centroid\n    moments = cv2.moments(bmask)\n    m00 = moments[\'m00\']\n    centroid_x, centroid_y = None, None\n    if m00 != 0:\n        centroid_x = int(moments[\'m10\']/m00)\n        centroid_y = int(moments[\'m01\']/m00)\n    # Assume no centroid\n    ctr = None\n    # Use centroid if it exists\n    if centroid_x != None and centroid_y != None:\n        ctr = (centroid_x, centroid_y)\n    return ctr\n\nvrep.simxFinish(-1)\nclientID = vrep.simxStart(\'127.0.0.1\', 19997, True, True, 5000, 5)\n\nif clientID!=-1:\n  print(\'Connected to remote API server\')\n  # get vision sensor objects\n  res, v0 = vrep.simxGetObjectHandle(clientID, \'vs1\', vrep.simx_opmode_oneshot_wait)\n  res, v1 = vrep.simxGetObjectHandle(clientID, \'vs2\', vrep.simx_opmode_oneshot_wait)\n  err, resolution, image = vrep.simxGetVisionSensorImage(clientID, v0, 0, vrep.simx_opmode_streaming)\n  time.sleep(1)\n  while (vrep.simxGetConnectionId(clientID) != -1):\n    # get image from vision sensor \'v0\'\n    err, resolution, image = vrep.simxGetVisionSensorImage(clientID, v0, 0, vrep.simx_opmode_buffer)\n    if err == vrep.simx_return_ok:\n        image_byte_array = array.array(\'b\', image)\n        #print(image_byte_array)\n        image_buffer = I.frombuffer("RGB", (resolution[0],resolution[1]), bytes(image_byte_array), "raw", "RGB", 0, 1)\n        img2 = numpy.asarray(image_buffer)\n      # try to find something green\n        ret_green = track_green_object(img2)\n        ret_red = track_red_object(img2)\n        ret_blue = track_blue_object(img2)\n      # overlay rectangle marker if something is found by OpenCV\n        if ret_green:\n            cv2.rectangle(img2,(ret_green[0]-5,ret_green[1]-5), (ret_green[0]+5,ret_green[1]+5), (0x99,0xff,0x33), 1)\n          # return image to sensor \'v1\'\n        if ret_red:\n            cv2.rectangle(img2,(ret_red[0]-3,ret_red[1]-5), (ret_red[0]+3,ret_red[1]+5), (0xff,0x33,0x33), 1)\n        if ret_blue:\n            cv2.rectangle(img2,(ret_blue[0]-3,ret_blue[1]-5), (ret_blue[0]+3,ret_blue[1]+5), (0x33,0xcc,0xff), 1)\n        img2 = img2.ravel()\n        #print(\'B=\',ret_blue[0],ret_blue[1])\n        #print(\'R=\',ret_red[0],ret_red[1])\n        #print(\'G=\',ret_green[0],ret_green[1])\n        vrep.simxSetVisionSensorImage(clientID, v1, img2, 0, vrep.simx_opmode_oneshot)\n    elif err == vrep.simx_return_novalue_flag:\n      print("no image yet")\n      pass\n    else:\n      print(err)\nelse:\n  print("Failed to connect to remote API Server")\n  vrep.simxFinish(clientID) \n', 'tags': '', 'url': 'Ag3-第十二週-影像辨識尋找球和桿子位置.html'}, {'title': 'Ag3-第十三週-影像辨識機器對打', 'text': '利用影像辨識抓取球與操作桿位置並使之對打， \n 由於影像需要處理時間，所以模擬速度越快抓取位置越不精確。 \n 已知錯誤: \n 如果球打到桿子後方會無法回擊。 \n \n vrep設定檔: tablefootball - 0507.ttt \n 程式檔: Image_Detection_play.py \n 程式碼: \n import vrep\nimport time\n\nfrom PIL import Image as I\nimport array\n\nimport cv2, numpy\n\n# function based on: \n#   https://github.com/simondlevy/OpenCV-Python-Hacks/blob/master/greenball_tracker.py\ndef speed(handle,speed):\n    vrep.simxSetJointTargetVelocity(clientID,handle,speed,vrep.simx_opmode_oneshot_wait)\ndef track_green_object(image):\n    # Blur the image to reduce noise100\n    blur = cv2.GaussianBlur(image, (5,5),0)\n    # Convert BGR to HSV\n    hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n    # Threshold the HSV image for only green colors\n    range = 15\n    lower_green = numpy.array([60-range,100,100])\n    upper_green = numpy.array([60+range,255,255])\n    # Threshold the HSV image to get only green colors\n    mask = cv2.inRange(hsv, lower_green, upper_green)\n    # Blur the mask\n    bmask = cv2.GaussianBlur(mask, (5,5),0)\n    # Take the moments to get the centroid\n    moments = cv2.moments(bmask)\n    m00 = moments[\'m00\']\n    centroid_x, centroid_y = None, None\n    if m00 != 0:\n        centroid_x = int(moments[\'m10\']/m00)\n        centroid_y = int(moments[\'m01\']/m00)\n    # Assume no centroid\n    ctr = None\n    # Use centroid if it exists\n    if centroid_x != None and centroid_y != None:\n        ctr = (centroid_x, centroid_y)\n    return ctr\n\ndef track_blue_object(image):\n    # Blur the image to reduce noise100\n    blur = cv2.GaussianBlur(image, (5,5),0)\n    # Convert BGR to HSV\n    hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n    # Threshold the HSV image for only green colors\n    range = 15\n    lower_red = numpy.array([0-range,100,100])\n    upper_red = numpy.array([0+range,255,255])\n    # Threshold the HSV image to get only green colors\n    mask = cv2.inRange(hsv, lower_red, upper_red)\n    # Blur the mask\n    bmask = cv2.GaussianBlur(mask, (5,5),0)\n    # Take the moments to get the centroid\n    moments = cv2.moments(bmask)\n    m00 = moments[\'m00\']\n    centroid_x, centroid_y = None, None\n    if m00 != 0:\n        centroid_x = int(moments[\'m10\']/m00)\n        centroid_y = int(moments[\'m01\']/m00)\n    # Assume no centroid\n    ctr = None\n    # Use centroid if it exists\n    if centroid_x != None and centroid_y != None:\n        ctr = (centroid_x, centroid_y)\n    return ctr\n    \ndef track_red_object(image):\n    # Blur the image to reduce noise100\n    blur = cv2.GaussianBlur(image, (5,5),0)\n    # Convert BGR to HSV\n    hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n    # Threshold the HSV image for only green colors\n    range = 15\n    lower_blue = numpy.array([120-range,100,100])\n    upper_blue = numpy.array([120+range,255,255])\n    # Threshold the HSV image to get only green colors\n    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n    # Blur the mask\n    bmask = cv2.GaussianBlur(mask, (5,5),0)\n    # Take the moments to get the centroid\n    moments = cv2.moments(bmask)\n    m00 = moments[\'m00\']\n    centroid_x, centroid_y = None, None\n    if m00 != 0:\n        centroid_x = int(moments[\'m10\']/m00)\n        centroid_y = int(moments[\'m01\']/m00)\n    # Assume no centroid\n    ctr = None\n    # Use centroid if it exists\n    if centroid_x != None and centroid_y != None:\n        ctr = (centroid_x, centroid_y)\n    return ctr\n\nvrep.simxFinish(-1)\nclientID = vrep.simxStart(\'127.0.0.1\', 19997, True, True, 5000, 5)\n\nif clientID!=-1:\n  print(\'Connected to remote API server\')\n  # get vision sensor objects\n  res, v0 = vrep.simxGetObjectHandle(clientID, \'vs1\', vrep.simx_opmode_oneshot_wait)\n  res, v1 = vrep.simxGetObjectHandle(clientID, \'vs2\', vrep.simx_opmode_oneshot_wait)\n  err, resolution, image = vrep.simxGetVisionSensorImage(clientID, v0, 0, vrep.simx_opmode_streaming)\n  err,Sphere_handle=vrep.simxGetObjectHandle(clientID,\'Sphere\',vrep.simx_opmode_oneshot_wait)\n  err,BRod_handle=vrep.simxGetObjectHandle(clientID,\'BRod\',vrep.simx_opmode_oneshot_wait)\n  err,BRev_handle=vrep.simxGetObjectHandle(clientID,\'BRev\',vrep.simx_opmode_oneshot_wait)\n  err,BMo_handle=vrep.simxGetObjectHandle(clientID,\'BMo\',vrep.simx_opmode_oneshot_wait)\n  err,RRev_handle=vrep.simxGetObjectHandle(clientID,\'RRev\',vrep.simx_opmode_oneshot_wait)\n  err,RMo_handle=vrep.simxGetObjectHandle(clientID,\'RMo\',vrep.simx_opmode_oneshot_wait)\n  err,RRod_handle=vrep.simxGetObjectHandle(clientID,\'RRod\',vrep.simx_opmode_oneshot_wait)\n  time.sleep(1)\n  while (vrep.simxGetConnectionId(clientID) != -1):\n    # get image from vision sensor \'v0\'\n    err, resolution, image = vrep.simxGetVisionSensorImage(clientID, v0, 0, vrep.simx_opmode_buffer)\n    if err == vrep.simx_return_ok:\n        image_byte_array = array.array(\'b\', image)\n        #print(image_byte_array)\n        image_buffer = I.frombuffer("RGB", (resolution[0],resolution[1]), bytes(image_byte_array), "raw", "RGB", 0, 1)\n        img2 = numpy.asarray(image_buffer)\n      # try to find something green\n        ret_green = track_green_object(img2)\n        ret_red = track_red_object(img2)\n        ret_blue = track_blue_object(img2)\n        #print(\'B=\',ret_blue[1],ret_blue[0])#y軸座標為0 x軸座標為1\n        #print(\'R=\',ret_red[1],ret_red[0])\n        #print(\'G=\',ret_green[1],ret_green[0])\n        if ret_green != None and ret_red != None and ret_blue != None:\n            Bv = float(ret_green[0])-float(ret_blue[0])\n            BBv=float(ret_green[1])-float(ret_blue[1])\n            Rv = float(ret_green[0])-float(ret_red[0])\n            RRv=float(ret_green[1])-float(ret_red[1])\n            if Bv<0.0:\n                speed(BMo_handle,Bv*-0.02)\n            elif Bv>0.0:\n                speed(BMo_handle,Bv*-0.02)\n            else:\n                speed(BMo_handle,0)\n            if Rv<0.0:\n                speed(RMo_handle,Rv*-0.02)\n            elif Rv>0.0:\n                speed(RMo_handle,Rv*-0.02)\n            else:\n                speed(RMo_handle,0)\n            if RRv<-10.0:\n                speed(RRev_handle,-2)\n            elif RRv>-10.0:\n                speed(RRev_handle,2)\n            else:\n                pass\n            if BBv<10.0:\n                speed(BRev_handle,-2)\n            elif BBv>10.0:\n                speed(BRev_handle,2)\n            else:\n                pass\n      # overlay rectangle marker if something is found by OpenCV\n        if ret_green:\n            cv2.rectangle(img2,(ret_green[0]-5,ret_green[1]-5), (ret_green[0]+5,ret_green[1]+5), (0x99,0xff,0x33), 1)\n          # return image to sensor \'v1\'\n        if ret_red:\n            cv2.rectangle(img2,(ret_red[0]-3,ret_red[1]-5), (ret_red[0]+3,ret_red[1]+5), (0xff,0x33,0x33), 1)\n        if ret_blue:\n            cv2.rectangle(img2,(ret_blue[0]-3,ret_blue[1]-5), (ret_blue[0]+3,ret_blue[1]+5), (0x33,0xcc,0xff), 1)\n        img2 = img2.ravel()\n        vrep.simxSetVisionSensorImage(clientID, v1, img2, 0, vrep.simx_opmode_oneshot)\n    elif err == vrep.simx_return_novalue_flag:\n      print("no image yet")\n      pass\n    else:\n      print(err)\nelse:\n  print("Failed to connect to remote API Server")\n  vrep.simxFinish(clientID) \n', 'tags': '', 'url': 'Ag3-第十三週-影像辨識機器對打.html'}, {'title': '結案報告', 'text': '', 'tags': '', 'url': '結案報告.html'}, {'title': '專案口頭簡報', 'text': '各組利用倉儲中的 Reveal.js 進行結案簡報 (結案口頭簡報) \n', 'tags': '', 'url': '專案口頭簡報.html'}, {'title': '專案報告書', 'text': '各組完成 html 與 pdf 格式之手足球專案結案報告 (文字結案報告書)', 'tags': '', 'url': '專案報告書.html'}]};